\documentclass{article}

% === Dependencies === %

\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage[backend=biber]{biblatex} % Imports biblatex package
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage[margin=1in]{geometry}
\usepackage{parskip} % Make space between paragraphs instead of indent
\usepackage[style=iso]{datetime2} % ISO style dates
\usepackage[utf8]{inputenc}

\addbibresource{sample.bib} % Import the bibliography file

% === Paragraphing === %

\makeatletter
\renewcommand\paragraph{\@startsection{paragraph}{4}{\z@}%
% display heading, like subsubsection
                                     {-3.25ex\@plus -1ex \@minus -.2ex}%
                                     {1.5ex \@plus .2ex}%
                                     {\normalfont\normalsize\bfseries}}
 \setcounter{secnumdepth}{4}
\setcounter{tocdepth}{4}
\makeatother

% === Theorem Styles === %

\newtheorem{definition}{Definition}[section]

% === Custom Commands === %

\newcommand{\eq}[1]{\begin{alignat*}{20}#1\end{alignat*}}
\newcommand{\eqn}[2]{\begin{equation}\label{#1}\begin{split}#2\end{split}\end{equation}}

\renewcommand{\vec}[1]{\boldsymbol{#1}}
\newcommand{\ran}[1]{\text{#1}}
\newcommand{\vecran}[1]{\mathbf{#1}}

\renewcommand{\O}{\mathcal{O}}
\newcommand{\V}{\mathcal{V}}
\renewcommand{\P}{\mathcal{P}}

% Sets
\newcommand{\F}{\mathbb{F}}
\newcommand{\G}{\mathbb{G}}
\newcommand{\Z}{\mathbb{Z}}

\newcommand\doubleplus{\mathbin{+\mkern-10mu+}} % concat-symbol
\newcommand{\dotp}[2]{\langle #1, #2 \rangle}
\newcommand{\opn}[1]{\operatorname{#1}}
\newcommand{\veclo}[1]{\vec{#1_{\opn{lo}}}}
\newcommand{\vechi}[1]{\vec{#1_{\opn{hi}}}}

% === Header === %

\title{Property based testing of Rust Bulletproofs using Hacspec}
\author{ 
Rasmus Kirk Jakobsen -- 201907084\\
Anders Wibrand Larsen -- 201906147\\
\textbf{Advisor:} Bas Spitters
}

\date{\today}

\begin{document}

\maketitle

\begin{center}
    Bachelor report (15 ECTS) in Computer Science\\
Department of Computer Science, Aarhus University\\
\end{center} 

\begin{center}
	\includegraphics[scale=0.4]{img/bulletproof-hacspec-2.png}
\end{center} 

\subsection*{Abstract:}

\tableofcontents

\newpage

% === Body === %

\section{Introduction:} \label{Introduction}
\section{Notation:} \label{notation}

% Should be moved to appendix
A table of notation used throughout this report:

\begin{center}
\begin{tabular}{ c l }
	$a$                       & A scalar \\
	$\vec{a}$                 & A vector \\
	$A$                       & A curve point \\
	$\vec{A}$                 & A vector of curve points \\
	$\ran{a}$                 & A scalar random variable \\
	$\vecran{a}$              & A vector of scalar random variables \\
	$\vecran{A}$              & A vector of random curve points \\
	$\veclo{a}$               & The first half of vector $\vec{a}$, ($\veclo{a} = [a_{1}, \cdots, a_{n/2}]$) \\
	$\vechi{a}$               & The second half of vector $\vec{a}$, ($\vechi{a} = [a_{n/2+1}, \cdots, a_{n}]$) \\
	$\mathbb{A}$              & A set \\
	$\mathbb{A}^n$            & A vector space of dimension $n$ \\ 
	$\mathbb{A}_n$            & A set whose elements are mod $n$ \\ 
	$\dotp{\vec{a}}{\vec{b}}$ & Dot product of $\vec{a}$ and $\vec{b}$ \\
	$\dotp{\vec{a}}{\vec{A}}$ & The sum of scalar-point products of $\vec{a}$ and $\vec{A}$ ($\dotp{\vec{a}}{\vec{A}} = a_1 A_1 + a_2 A_2 + \cdots + a_n A_n$) \\
\end{tabular}
\end{center}

\section{Prerequisites:}

In this section we will be going over the necessary background knowledge
to understand the results of the work in this project.

\subsection{Finite Field Arithmetic:} \label{Finite Field Arithmetic}

We start with \textit{fields} and the operations defined within
them, as the operations we will later define that work on elliptic
curves are built on fields.

\begin{definition}[Field]
	A field is a set $\F$, along with the \textit{addition} and
	\textit{multiplication} operations. These two operations must
	uphold the so called \textit{field axioms}:

	\begin{itemize}
		\item Associativity of addition and multiplication:
		$\forall a,b,c \in \F : a + (b + c) = (a + b) + c \land a \cdot (b \cdot c) = (a \cdot b) \cdot c$
		\item Commutativity of addition and multiplication:
		$\forall a,b \in \F : a+b=b+a \land a \cdot b = b \cdot a$
		\item Additive and multiplicative identity:
		$\exists 0,1 \in \F : a + 0 = a \land a \cdot 1 = a$
		\item Additive inverses:
		$\forall a \in \F,\ \exists {-a} \in \F : a + ({-a}) = 0$
		\item Multiplicative inverses:
		$\forall a \neq 0 \in \F,\  \exists a^{-1} \in \F : a \cdot a^{-1} = 1$
		\item Distributivity over addition:
		$\forall a,b,c \in \F : a \cdot (b + c) = (a \cdot b) + (a \cdot c)$
	\end{itemize}
\end{definition}

Note that this also means that subtraction and division is defined,
due to the existance of the additive and multiplicative inverses
respectively:

\eq{
	a-b         &= a + (-b) \\
	\frac{a}{b} &= a \cdot b^{-1}
}

Corrolarily, this leads us to \textit{finite fields}:

\begin{definition}[Finite Field]
	A finite field, is a field that contains a finite number of elements.
\end{definition}

One of the most commonly used types of finite fields, and those used
throughout this report are \textit{Prime Fields:} 

\begin{definition}[Prime Field]
	A prime field $\F_p$ is a finite field with elements $[0,p-1]$
	where each operation is performed over integers modulo $p$ with $p$ being a prime number.
\end{definition}

Something important to note about this definition is that inverses in
this kind of field are also positive whole numbers. This will come up
again in section \ref{implementing-ristretto} with regards to the code.

\subsection{Elliptic Curve:}\label{elliptic-curves}

To start our explanation of elliptic curves we add a few definitions:

\begin{definition}[Elliptic Curves]
	An elliptic curve, $E$, is an algebraic curve defined over a prime field, $\F_p$, defined by the formula:
	$$y^2 = x^3 + ax + b$$
\end{definition}

\begin{definition}[EC Additive Identity]
	Let $\O$ be the point where $y = \infty$. For every point, $P$,
	on $E$ the following property holds:
	$P + \O = \O + P = P$.
\end{definition}

\begin{definition}[EC Negation]
	Let $P = (x,y)$ be a point on $E$. The negation of $P$, called $-P$
	is defined as the mirror of P over the x-axis, or $-P = (x,-y)$.
\end{definition}

\begin{definition}[EC Addition]
	Let $\ell$ be a line intersecting $E$ at three points, $P$, $Q$ and
	$-R$. The group operation: Addition defined on two points is defined
	as:
	$$P + Q = {-R}$$
\end{definition}

\begin{definition}[EC Doubling]
	let $\ell$ be the tangent to the point $P$ on $E$, which intersects
	points $P$ and $-R$. The group operation: point doubling on P is
	defined as:
	$$2P = P + P = R$$
\end{definition}

An important thing to note about point addition. In the case where
you add points $P$ and $Q$ where $\ell$ is a tangent to $P$ then $P +
Q = -P$. This is due to the fact that the \textit{only} case in which
this can happen is when $Q = -(P + P)$ and thus you get $P + Q = P +
(-(P + P)) = -P$. Another similar case is using point doubling on any
point $P = (x,0)$ on $E$. The tangent of $P$ do not intersect
a second point. However note that the negation of $P$ here is $-P =
(x,-0) = (x,0) = P$. Thus point doubling on these points is equivalent
to the equation $P + (-P) = \O$.

From these definitions we can extrapolate two more definitions:

\begin{definition}[EC Subtraction]
	Let $P$ and $Q$ be elliptic curve points. The group operation:
	Subtraction is defined by:
	$$P-Q = P + (-Q)$$
\end{definition}

\begin{definition}[EC Scalar Multiplication]
	Let $m$ be a scalar and let $P$ be a point on $E$. The group operation:
	Scalar multiplication is defined by adding $P$ to itself $m$ times and
	denoted a $m\cdot P$.
\end{definition}

Due to the absence of scalar division it is impossible to
multiply by anything other than integers as we cannot have something akin to $2.5 \cdot P = \frac{5\cdot P}{2}$. Therefore scalars are always integers when doing computations for elliptic curves. Multiplying by $0$ will
naturally yield the identity element $\mathcal{O}$ by definition.
Additionally multiplying by a negative integer, ${-m}$, is defined as
$-m\cdot P = m\cdot ({-P})$. 

The particular curve used for our implementation, as well as the
implementation of the Rust bulletproofs, is a special curve from a subset
of curves known as Montgomery curves. These curves are defined by the
formula: $By^2 = x^3 + Ax^2 + x$. Curves of this form have a birational
equivalence with a different set of curves, known as Twisted Edwards
curves. Our implementation, as well as the implementation we test against
utilize this aspect in their internal representations of points on the
curve.

For our implementation of bulletproofs, seeing as we needed to test it
against an existing implementation we made use of the same elliptic
curve, as well as gained an understanding of the basics of elliptic
curve cryptography. The elliptic curve in question is Curve25519, which
is widely used in encryption as is the case here. Curve25519, henceforth
shortened to 25519, is defined by the following formula:

$$y^2 = x^3 + 48662x^2 + x$$

This curve is defined over the prime field $K = 2^{255} - 19$ and base
point defined at $x = 9$ with the positive $y$ value. This results in a
sub-group of order $2^{252} + 2774231777737235353585$, which has a
co-factor of $8$. This co-factor would make cryptocurrencies that use
Curve25519 elliptic curves vulnerable to the so-called 'Double Spending
Vulnerability'. However the implementation known as Ristretto circumvents
this by eliminating the co-factor. For more detail see \ref{ristretto}

\subsection{Bulletproofs:}\label{Bulletproofs}

The ultimate goal of this project has been to implement bulletproofs in
Hacspec, using property-based testing to ensure it is equivalent to the
implementation done in Rust, using 25519. A bulletproof is a
non-interactive aggregation of rangeproofs using Pedersen commitments.
The following section will describe each of these terms in greater detail
on a theoretic level.

\subsubsection{Pedersen Commitment:}

A Pedersen commitment is a commitment scheme defined by a certain
property we will go into a little later. For our purposes we redefine
the scheme to work with commitments to elliptic curve points rather than
a value. First a single point $G$ on the chosen elliptic curve, in this
case 25519, is chosen. This point will be the so-called generator. For 25519 we use the point
we previously defined as the base point with x = 9 and positive y. 

Our adaptation of the Pedersen commitment scheme will involve point
addition on the elliptic curve, rather than multiplication. This will
have the desired effect of perfect hiding for Pedersen commitments. The
points that we will add together to hide our commitment works using some
amount of randomness which ensures the hiding property while also
allowing for a decent binding property. Not perfect, as this is impossible
alongside perfect hiding. 

\begin{definition}[Pedersen Commitment]
	A Pedersen commitment, to some message, $a$, with a randomly chosen
	integer, $r$, is defined as:

	$$rH + aG$$

	where $G$ is a canonical generator for the curve and $H$ is a curve point where no one knows $q$ such that $H = qG$.
\end{definition}

Here $r$ serves as our perfect hiding, $G$ is our generator for the
curve and $H$ is another curve point where no one knows $q$ such that
$H = qG$. This ensures perfect hiding as there is a nearly infinite
amount of possible combinations of two points that can add to any given
point. However while that is true, it does not provide perfect binding by
definition of binding and hiding. From here on we will refer to a
commitment to a message, $a$, with random value, $r$, as $C(a,r)$.

The most important property of Pedersen commitments however is
that pedersen commitments have the property of \textit{Additive
Homomorphism}:

\begin{definition}[Additive Homomorphism]
	For any two Pedersen commitments $C(a_1,r_1), C(a_2,r_2)$ we have:
	$$ C(a_1,r_1) + C(a_2,r_2) = C(a_1 + a_2, r_1 + r_2)$$
\end{definition}

This is simple to show by simply applying the definition of Pedersen
commitments: 

\eq{
	C(a_1,r_1) + C(a_2,r_2) &= r_1H + a_1G  + r_2H + a_2G \\
	                        &= (r_1 + r_2)H + (a_1 + a_2)G \\
	                        &= C(a_1+a_2,r_1+r_2)
}

Which ensures a homomorphism between the sum of commitments and the
commitment to the sum. This property will become vital when proving zero
knowledgeness later. 

Expanding on the \textit{Vector Pedersen Commitment}:
\begin{definition}[Vector Pedersen Commitment]
	A Vector Pedersen Commitment, to some vector of messages,
	$\textbf{v}$, with a randomly chosen integer, $r$,
	is defined as:

	$$rH + \textbf{vG}$$

	where $\textbf{G}$ is a vector of canonical generators for
	the curve and $H$ is still a curve point where no one knows q such that $H = qG$.
\end{definition}

\subsubsection{Inner Product Proof:}
We have two parties, a prover, $\P$, and a verifier, $\V$. $\P$ wants to
prove to $\V$ that he has knowledge of two vectors $\vec{a}$, $\vec{b}$
and know their dot product $\dotp{\vec{a}}{\vec{b}} = c$. The prover
could simply send the verifier $\vec{a}$, $\vec{b}$ and $c$ but this
would take up $O(n)$ bandwidth and time to verify, instead we will use a
compression technique included in the bulletproofs paper allowing for
just $O(log_2(n))$ bandwidth and time to verify.

\paragraph{Provers Algorithm:}
We have the following definitions:

\eqn{def1}{
	\vec{a}, \vec{b} &\in \Z^n_p \\
	\vec{G}, \vec{H} &\in \G^n \\
}
\eqn{def2}{
	P &= \dotp{\vec{a}}{\vec{G}} + \dotp{\vec{b}}{\vec{H}} \\
	c &= \dotp{\vec{a}}{\vec{b}} \\
}

Here $P$ is a Pedersen Commitment but crucially \textit{there is no
blinding}, this blinding will be introduced later on in the range proofs
section (\ref{range-proofs}). We will introduce a combined form of $P$
and $c$ in the form of $P'$:

\eq{
	P' &= \dotp{\vec{a}}{\vec{G}} +
	      \dotp{\vec{b}}{\vec{H}} +
	      \dotp{\vec{a}}{\vec{b}}Q \\
}

This will be useful, because it will allow us redefine $\vec{a},
\vec{b}, \vec{G}, \vec{H}$ into a shorter format while keeping the
properties in equation \ref{def2} as invariants.

\eq{
	\vec{a}^{(k-1)} &= \veclo{a} &&\cdot \ran{u}_k      &&+ \ran{u}^{-1}_k &&\cdot \vechi{a} \\
	\vec{b}^{(k-1)} &= \veclo{b} &&\cdot \ran{u}^{-1}_k &&+ \ran{u}_k      &&\cdot \vechi{b} \\
	\vec{G}^{(k-1)} &= \veclo{G} &&\cdot \ran{u}^{-1}_k &&+ \ran{u}_k      &&\cdot \vechi{G} \\
	\vec{H}^{(k-1)} &= \veclo{H} &&\cdot \ran{u}_k      &&+ \ran{u}^{-1}_k &&\cdot \vechi{H} \\
}

The random variable $\ran{u}$ is sent by the verifier to
ensure that it is indeed random. To make the inner product
proof \textit{non-interactive}, the Fiat-Shamir Heuristic
(\ref{fiat-shamir-heuristic}) can be used.  Notice, that these redefined
vectors will have a length half of that of the original vectors. From
these new vectors we will define a new compressed $P$:

\eq{
	P_{k-1} =
	\dotp{\vec{a}^{(k-1)}}{\vec{G}^{(k-1)}} +
	\dotp{\vec{b}^{(k-1)}}{\vec{H}^{(k-1)}} +
	\dotp{\vec{a}^{(k-1)}}{\vec{b}^{(k-1)}} \cdot Q
}

Notice that $P$ is still defined the same way, and that the property
$c^{k-1} = \dotp{\vec{a}^{k-1}}{\vec{b}^{k-1}}$ still holds. If we
substitute our defined variables:

\eq{
	P_{k-1} = \: \:
	&\dotp
		{        \veclo{a} &&\cdot u_k      &&+ u_k^{-1} &&\cdot \vechi{a}}
		{&&\quad \veclo{G} &&\cdot u_k      &&+ u_k^{-1} &&\cdot \vechi{G}}
	+ \\
	&\dotp
		{        \veclo{b} &&\cdot u_k^{-1} &&+ u_k      &&\cdot \vechi{b}}
		{&&\quad \veclo{H} &&\cdot u_k^{-1} &&+ u_k      &&\cdot \vechi{H}}
	+ \\
	&\dotp
		{        \veclo{a} &&\cdot u_k      &&+ u_k^{-1} &&\cdot \vechi{a}}
		{&&\quad \veclo{b} &&\cdot u_k^{-1} &&+ u_k      &&\cdot \vechi{b}}
	\cdot Q \\
}

And group the terms:

\eq{
	P_{k-1} = \: \:
	        &\dotp{\veclo{a}}{\veclo{G}}            +
	         \dotp{\vechi{a}}{\vechi{G}}          &&+
	u^2_k    \dotp{\veclo{a}}{\vechi{G}}          &&+
	u^{-2}_k \dotp{\veclo{a}}{\vechi{G}}            +\\
	        &\dotp{\veclo{b}}{\veclo{H}}            +
	         \dotp{\vechi{b}}{\vechi{H}}          &&+
	u^2_k    \dotp{\veclo{b}}{\vechi{H}}          &&+
	u^{-2}_k \dotp{\veclo{b}}{\vechi{H}}            +\\
	       &(\dotp{\veclo{a}}{\veclo{b}}            +
		       \dotp{\vechi{a}}{\vechi{b}}) \cdot Q &&+
	(u^2_k   \dotp{\veclo{a}}{\veclo{b}}          &&+
	u^{-2}_k \dotp{\vechi{a}}{\vechi{b}}) \cdot Q
}

Finally, we define variables $L_k$ and $R_k$ to further simplify: 

\eq{
	&P_{k-1} &&= P_k + u^2_k \cdot L_k + u^{-2}_k \cdot R_k \\
	&\textbf{where:} \\
	&L_k     &&= \dotp{\veclo{a}}{\vechi{G}} +
	             \dotp{\vechi{b}}{\veclo{H}} + 
	             \dotp{\veclo{a}}{\vechi{b}} \cdot Q \\
	&R_k     &&= \dotp{\vechi{a}}{\veclo{G}} +
	             \dotp{\veclo{b}}{\vechi{H}} +
	             \dotp{\vechi{a}}{\veclo{b}} \cdot Q \\
}

This process is repeated $log_2(n)$ times, until we get:

\eq{
	P_0 &= a^{(0)}_0 G^{(0)}_0 + b^{(0)}_0 H^{(0)}_0 + a^{(0)}_0 b^{(0)}_0 Q \\
	P_0 &= P_k + \sum^k_{i=1}(L_i u^2_i + u^{-2}_i R_i)
}

The prover finally returns $a^{(0)}_0$, $b^{(0)}_0$, $\vec{L}$
and $\vec{R}$

\paragraph{Verifiers Algorithm}
The verifiers algorithm...

\subsubsection{Zero Knowledge Proofs:}
\subsubsection{Range Proofs:}\label{range-proofs}

A range-proof is a zero-knowledge proof which seeks to prove that for some value v, v lies within the range of $[0,2^n)$ without revealing v or any additional information about v, thus zero-knowledge. We wish to express this property of v in a single inner product to be able to use an innerproduct proof as described above. 

If we let $\vec{a}$ be v expressed in bits and let $\vec{2^n}$ be the vector of powers of 2 i.e. [1,2,4,8.. $2^{n-1}$] then we know the following:

\eq{z\dotp{\vec{a}}{\vec{2^n}} = v}

However this is not enough as we need a guarantee that a is also bits. This can be proven by the following property: 

\eq{\vec{a}\circ (\vec{a} - \vec{1}) = \vec{0}}

This property will only hold if $\vec{a}$ has entries that are either 0 or 1. Additionally due to needing to commit to both $\vec{a}$ and $\vec{a} - \vec{1}$ we will rename these to $\vec{a_L}$ and $\vec{a_R}$ respectively and add another property to show the relationship between these two which gives us the following final innerproducts:

\eq{
	\dotp{\vec{a_L}}{\vec{2^n}} = v \\
	\vec{a_L}\circ \vec{a_R} = \vec{0} \\
	(\vec{a_L} - \vec{1}) - \vec{a_R} = \vec{0}
}

We wish to combine these properties into a single statement which we can manipulate into the kind of inner product we wish. To do this we observe that $\vec{a} = \vec{0} \iff \forall y\in\mathbb{Z}: \dotp{\vec{a}}{\vec{y^n}} = \vec{0}$. So we can let the verifier chose a y and then we get a new set of statements:

\eq{
	\dotp{\vec{a_L}}{\vec{2^n}} = v \\
	\dotp{\vec{a_L} - \vec{1} - \vec{a_R}}{y^n} = 0 \\
	\dotp{\vec{a_L}}{\vec{a_R}\circ \vec{y^n}} = 0
}

Next we let the verifier chose another scalar z, and can thus combine the three statements above to the following single statement:

\eq{
	z^2v = 
	z^2\dotp{\vec{a_L}}{\vec{2^n}} +
	z\dotp{\vec{a_L} - \vec{1} - \vec{a_R}}{y^n} +
	\dotp{\vec{a_L}}{\vec{a_R}\circ \vec{y^n}}
}

With this we have condensed the properties we wish to describe into a single statement. However this is not enough. We wish to express this as a single inner product where $\vec{a_L}$ appears only on the left-side of the inner product and $\vec{a_R}$ appears only on the right side and all non-secret terms are factored out. 

\subsubsection{Bulletproofs:}

In the most basic terms a Bulletproof is a zero-knowledge aggregated range-proof which proves that one or most likely more values lie within a certain range: $[0,2^n)$ for some integer n. This is done by aggregating range-proofs for each individual value into a single proof which, if verified proves that each value given lies within the range while giving away no more information about any of the values. This is done by using a multi-party protocol where a 'party' is created for each value that needs to be proven and each party will converse with the so-called 'dealer' who is responsible for collecting the various commitments from the parties and generating challenges which is used by all parties. At the very end the dealer will then collect all the individual rangeproofs for each value and aggregate them. 

The steps used to do this are the same steps used in the construction of a rangeproof with an additional step at the end which is the aggregation step which combines all the individual rangeproofs into a single proof.
%\section{State of the art:}

\subsubsection{Fiat-Shamir Heuristic}\label{fiat-shamir-heuristic}
% Include the recently found vulnerability

\subsection{Hacspec:} \label{Hacspec}

Hacspec is a subset of the programming language of Rust, designed in a
way that makes it easy to compile into theorem solvers such as Coq or F*.
The cost for having this property is a reduction in certain conventions
available in Rust not being present in Hacspec. This is a double edged
sword, both making the language simple, but also making it harder to
express certain abstract ideas. The language however is still in
development, balancing and adding features to the language.

All code written for this project was written to be Hacspec
compliant.  Our implementation is a specification meant to
be simply understood compared to a more obfuscated, but highly
optimized implementation. We will use property based testing with
QuickCheck\footnote{\url{https://github.com/BurntSushi/quickcheck}}
to check our Bulletproofs implementation against the Dalek-Cryptography
Bulletproofs\footnote{\url{https://github.com/dalek-cryptography/bulletproofs}}.
We have also created a minimal linear algebra library, in hacspec,
since it was needed for the bulletproofs implementation. Property
based testing using QuickCheck is also used for this library, testing
it against the nalgebra\footnote{\url{https://nalgebra.org/}}.

At a later time our implementation could to be compiled to Coq or F* and
proof-checked, leading to better guarantees about our implementation.
This is however not in the scope of this paper and is left to future
work. % mere her

\subsection{Ristretto:} \label{ristretto}

Ristretto is a specification of elliptic curve cryptography, created for
the specific purpose of eliminating unwanted co-factors. This was done
in order to circumvent the double-spending vulnerability. This is done
using a so-called quotient group. Also appropriately called a Factor
Group, a Quotient Group is a type of group, which takes elements from a
larger group and, using an equivalence relation, maps elements that are
'similar' to the same element in the quotient group, while preserving
most of the group structure. The remaining elements are factored out,
leaving a group with the same operations, but fewer elements. What
this means for Ristretto is that it takes points on an elliptic curve
and eliminates the co-factor by simply mapping them down to their
'equivalent' elements. This is the reason for Ristretto's somewhat
unorthodox method of doing operations, as it must ensure that each
element is computed to the proper element in the quotient group. This is
also done, in part, to allow the user to use points that are NOT in the
quotient group without worry as any computation done with these points
is automatically mapped to their proper element, thus eliminating the
rather computationally expensive operation of checking if a point is
on the proper curve.

Additionally the internal representation of the Montgomery curve we wish
to eliminate the co-factor for, is its equivalent Twisted Edwards Curve,
which is done to more easily factor points from the original curve into
the quotient group. Additionally Ristretto's equality method ensures
that equivalent representations of points on the curve are equal, even
if they are not factored into the quotient group yet. Additionally
from its encoding and decoding methods, equivalent points are encoded
to the same bitstring, and are therefore decoded into their refactored
quotient group element.

The exposed functions that were implemented are the encoding and decoding
functions, the equality function to compare points, the addition function
over points, point negation, and the derived functions from these,
namely point doubling, point subtraction and scalar multiplication. And
the final function is the One Way Map function. This function is not
entirely necessary for our purposes, but having it allows outside users
to more easily generate points from simple byte sequences, and 
also makes generating random points for testing much easier.

\section{Contributions:}

\subsection{Linear Algebra Library Specification:}
\begin{itemize}
	\item Vectors vs Matrices 
	\item Describe formulas, with sources (Dot product) 
	\item Generics :(
	\item Cloning
	\item Double indexing
	\item QuickCheck
\end{itemize} 

It was decided that the specification should of course consist of what we
need, but also of some general linear algebra functions that could be
used for others who might want to use it. The following functions was
decided to be part of the specification:

\begin{itemize}
	\item Instantiate matrix
	\item Instantiate zero filled matrix
	\item (Instantiate one filled matrix)
	\item Instantiate identity matrix
	\item Transposition
	\item Slicing
	\item (Scalar Multiplication)
	\item Addition
	\item Subtraction
	\item Hadamard product
	\item Matrix Multiplication
\end{itemize}

No generalized standard for Linear Algebra Specification.

\subsection{Implementing Ristretto:} \label{implementing-ristretto}

For our Ristretto implementation on 25519 there
exists an IETF-standard specification of exactly
this, which was used as a guide for our implementation.
\footnote{\url{https://www.ietf.org/archive/id/draft-irtf-cfrg-ristretto255-00.html}}
This specification was very helpful and after inspecting the code we
are testing against closely, it is clear that they used this standard
as well.

The most important things to note about this standard, outside the
explicit formulas used for its various methods are which functions and
internal representations we are allowed to expose to the outside. Namely
that the only functions we may expose were encoding of points, decoding
of encoded points, the map which is used for creating points, point
addition, point negation, point subtraction, scalar multiplication. The
last two were allowed purely from being derivable from repeated
application of point addition and/or negation. Some things that were not
allowed to be exposed under any circumstances, are the internal
representations of either points or its field elements or any functions
that are not the ones mentioned above, which is as expected for something
that is meant to be a thin layer of abstraction beneath an implementation
of 25519.

Each internal point representation is composed of four field elements
$(X : Y : Z :T)$. Field-elements, as defined by the standard are values
modulo p, with p being the prime field for 25519, $2^{255} - 19$. This
was achieved using the \texttt{public\_nat\_mod!} macro which defines
fields over certain values which just so happen to accept hex values as
modulo values, which was very convenient. With this we are now able to
create field elements using various functions and properties that are
native to the type created by \texttt{public\_nat\_mod!}. Most of the
standard integer operators like addition, subtraction and multiplication
are implemented for these field elements for example. An important thing
to note is that the internal calculations for division is done using
integer arithmetic rather than finite field arithmetic, however the
few times where division is used directly it is ensured that the result
in finite field arithmetic is equal to the integer arithmetic solution.

Additionally the standard, specified a series of constants. These
constants were too large to be implemented as integers. Additionally
hacspec did not allow for us to simply use the \texttt{from\_hex()}
method. As such, after converting each of these constants into their
corresponding hex-values, we built them as byte sequences for which
we had an equivalent \texttt{from\_byte\_seq\_be} which created the
correct field elements we wanted.

While it is impossible for a legal point to be encoded and then have the
decoding on its encoding fail, the decoding method has several checks
that ensure that the input given is legal. The primary reason for this
is that decoding is a method available to the client and as such there is
no guarantee that the byte-strings they want to decode are necessarily
legal points that they first encoded properly, but could be artificially
constructed byte-strings. We want to avoid this and thus the standard has
a list of properties the byte-string input must satisfy for the decoding
to be canonical and thus give a proper point as a result. 

\subsection{Implementing Bulletproofs:}

Our bulletproofs implementation was implemented on the foundation of our
implementations of Linear Algebra and Ristretto. The first and simplest
step was implementing Pedersen commitments to single values as well as to
vectors. From our implementation of Ristretto we can easily add points to
each other and multiply points by a scalar. This is essentially the only
thing a Pedersen commitment is. Additionally we needed it to support
vector commitments. From our implementation of Linear Algebra we could
easily adapt this into the code. This implementation was nearly trivial
given the base we built it upon.

The next step in the process towards implementing Bulletproofs is the
inner product proof. The implementation of which does not lean itself
against our Ristretto implementation as our implementation of Pedersen
commitments did, however it does utilize said Pedersen commitments. 


The final part was implementing the bulletproof methods themselves. 

\subsection{Analysis of coding stuff:}

\subsection{Summary of coding stuff:}

\subsection{Conclusions on our work:}

\section{Future work:}

\section{Acknowledgements:}

%% TAK TIL FRANZISKUS
%% Lasse?

\section{References}
\printbibliography


\end{document}
