\documentclass{article}

% === Dependencies === %

\usepackage{amsfonts}
\usepackage{amsmath}
\usepackage{amsthm}
\usepackage[backend=biber]{biblatex} % Imports biblatex package
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage[margin=1in]{geometry}
\usepackage{parskip} % Make space between paragraphs instead of indent
\usepackage[style=iso]{datetime2} % ISO style dates
\usepackage[utf8]{inputenc}

\addbibresource{sample.bib} % Import the bibliography file

% === Theorem Styles === %

\newtheorem{definition}{Definition}[section]

% === Custom Commands === %

\newcommand{\eq}[1]{\begin{equation*}\begin{split}#1\end{split}\end{equation*}}
\newcommand{\eqNumbered}[1]{\begin{equation}\begin{split}#1\end{split}\end{equation}}

\renewcommand{\vec}[1]{\mathbf{#1}}

\newcommand{\V}{\mathcal{V}}
\renewcommand{\P}{\mathcal{P}}
\renewcommand{\O}{\mathcal{O}}
\newcommand{\F}{\mathbb{F}}

% === Header === %

\title{Property based testing of Rust Bulletproofs using Hacspec}
\author{ 
Rasmus Kirk Jakobsen -- 201907084\\
Anders Wibrand Larsen -- 201906147\\
\textbf{Advisor:} Bas Spitters
}

\date{\today}

\begin{document}

\maketitle

\begin{center}
    Bachelor report (15 ECTS) in Computer Science\\
Department of Computer Science, Aarhus University\\
\end{center} 

\begin{center}
	\includegraphics[scale=0.4]{img/bulletproof-hacspec-2.png}
\end{center} 

\subsection*{Abstract:}

\tableofcontents

\newpage

% === Body === %

\section{Introduction:} \label{Introduction}
\section{Notation:} \label{notation}

We denote scalar in lowercase ($x$), vectors in bold lowercase
($\vec{v}$), sets are capitalized ($S$), as are Elliptic Curve
Points ($P$). We also have the sum of scalar-point products, with a vector of scalars $\vec{v}$ and a vector of curve points $\vec{P}$, written as:
$$\vec{vP} = v_1 P_1 + v_2 P_2 + \cdots + v_n P_n$$

\section{Prerequisites:}

In this section we will be going over the necessary background knowledge
to understand the results of the work in this project.

\subsection{Finite Field Arithmetic:} \label{Finite Field Arithmetic}

We start with \textit{fields} and the operations defined within
them, as the operations we will later define that work on elliptic
curves are built on fields.

\begin{definition}[Field]
	A field is a set $\F$, along with the \textit{addition} and
	\textit{multiplication} operations. These two operations must
	uphold the so called \textit{field axioms}:

	\begin{itemize}
		\item Associativity of addition and multiplication:
		$\forall a,b,c \in \F : a + (b + c) = (a + b) + c \land a \cdot (b \cdot c) = (a \cdot b) \cdot c$
		\item Commutativity of addition and multiplication:
		$\forall a,b \in \F : a+b=b+a \land a \cdot b = b \cdot a$
		\item Additive and multiplicative identity:
		$\exists 0,1 \in \F : a + 0 = a \land a \cdot 1 = a$
		\item Additive inverses:
		$\forall a \in \F,\ \exists {-a} \in \F : a + ({-a}) = 0$
		\item Multiplicative inverses:
		$\forall a \neq 0 \in \F,\  \exists a^{-1} \in \F : a \cdot a^{-1} = 1$
		\item Distributivity over addition:
		$\forall a,b,c \in \F : a \cdot (b + c) = (a \cdot b) + (a \cdot c)$
	\end{itemize}
\end{definition}

Note that this also means that subtraction and division is defined,
due to the existance of the additive and multiplicative inverses
respectively:

\eq{
	a-b         &= a + (-b) \\
	\frac{a}{b} &= a \cdot b^{-1}
}

Corrolarily, this leads us to \textit{finite fields}:

\begin{definition}[Finite Field]
	A finite field, is a field that contains a finite number of elements.
\end{definition}

The most common types of finite fields, and those used throughout this report are \textit{Prime Fields:} 

\begin{definition}[Prime Field]
	A prime field $\F_p$ is a finite field with elements $[0,p-1]$
	where each operation is performed over integers modulo $p$.
\end{definition}

Something important to note about this definition is that inverses in
this kind of field are also positive whole numbers. This will come up
again in section \ref{implementing-ristretto} with regards to the code.

\subsection{Elliptic Curve:}\label{elliptic-curves}

To start our explanation of elliptic curves we add a few definitions:

\begin{definition}[Elliptic Curves]
	An elliptic curve, $E$, is an algebraic curve defined over a prime field, $\F_p$, defined by the formula:
	$$y^2 = x^3 + ax + b$$
\end{definition}

\begin{definition}[EC Additive Identity]
	Let $\O$ be the point where $y = \infty$. For every point, $P$,
	on $E$ the following property holds:
	$P + \O = \O + P = P$.
\end{definition}

\begin{definition}[EC Negation]
	Let $P = (x,y)$ be a point on $E$. The negation of $P$, called $-P$
	is defined as the mirror of P over the x-axis, or $-P = (x,-y)$.
\end{definition}

\begin{definition}[EC Addition]
	Let $\ell$ be a line intersecting $E$ at three points, $P$, $Q$ and
	$-R$. The group operation: Addition defined on two points is defined
	as:
	$$P + Q = {-R}$$
\end{definition}

\begin{definition}[EC Doubling]
	let $\ell$ be the tangent to the point $P$ on $E$, which intersects
	points $P$ and $-R$. The group operation: point doubling on P is
	defined as:
	$$2P = P + P = R$$
\end{definition}

An important thing to note about point addition. In the case where
you add points $P$ and $Q$ where $\ell$ is a tangent to $P$ then $P +
Q = -P$. This is due to the fact that the \textit{only} case in which
this can happen is when $Q = -(P + P)$ and thus you get $P + Q = P +
(-(P + P)) = -P$. Another similar case is using point doubling on any
point $P = (x,0)$ on $E$. The tangent of $P$ do not intersect
a second point. However note that the negation of $P$ here is $-P =
(x,-0) = (x,0) = P$. Thus point doubling on these points is equivalent
to the equation $P + (-P) = \O$.

From these definitions we can extrapolate two more definitions:

\begin{definition}[EC Subtraction]
	Let $P$ and $Q$ be elliptic curve points. The group operation:
	Subtraction is defined by:
	$$P-Q = P + (-Q)$$
\end{definition}

\begin{definition}[EC Subtraction]
	Let $m$ be a scalar and let $P$ be a point on $E$. The group operation:
	Scalar multiplication is defined by adding $P$ to itself $m$ times and
	denoted a $m\cdot P$.
\end{definition}

Due to the absence of scalar division it is therefore impossible to
multiply by anything other than integers as we cannot have something
like $2.5 \cdot P = \frac{5\cdot P}{2}$. Multiplying by $0$ will
naturally yield the identity element $\mathcal{O}$ by definition.
Additionally multiplying by a negative integer, ${-m}$, is defined as
$-m\cdot P = m\cdot ({-P})$. 

The particular curve used for our implementation, as well as the
implementation of the Rust bulletproofs, is a special curve from a subset
of curves known as Montgomery curves. These curves are defined by the
formula: $By^2 = x^3 + Ax^2 + x$. Curves of this form have a birational
equivalence with a different set of curves, known as Twisted Edwards
curves. Our implementation, as well as the implementation we test against
utilize this aspect in their internal representations of points on the
curve.

For our implementation of bulletproofs, seeing as we needed to test it
against an existing implementation we made use of the same elliptic
curve, as well as gained an understanding of the basics of elliptic
curve cryptography. The elliptic curve in question is Curve25519, which
is widely used in encryption as is the case here. Curve25519, henceforth
shortened to 25519, is defined by the following formula:

$$y^2 = x^3 + 48662x^2 + x$$

This curve is defined over the prime field $K = 2^{255} - 19$ and base
point defined at $x = 9$ with the positive $y$ value. This results in a
sub-group of order $2^{252} + 2774231777737235353585$, which has a
co-factor of $8$. This co-factor would make cryptocurrencies that use
Curve25519 elliptic curves vulnerable to the so-called 'Double Spending
Vulnerability'. However the implementation known as Ristretto circumvents
this by eliminating the co-factor. For more detail see \ref{ristretto}

\subsection{Bulletproofs:}\label{Bulletproofs}

The ultimate goal of this project has been to implement bulletproofs in
Hacspec, using property-based testing to ensure it is equivalent to the
implementation done in Rust, using 25519. A bulletproof is a
non-interactive aggregation of rangeproofs using Pedersen commitments.
The following section will describe each of these terms in greater detail
on a theoretic level.

\subsubsection{Pedersen Commitment:}

A Pedersen commitment is a commitment scheme defined by a certain
property we will go into a little later. For our purposes we redefine
the scheme to work with commitments to elliptic curve points rather than
a value. First a single point $G$ on the chosen elliptic curve, in this
case 25519. This point will be our generator. for 25519 we use the point
we previously defined as the base point. 

Our adaptation of the Pedersen commitment scheme will involve point
addition on the elliptic curve, rather than multiplication. This will
have the desired effect of perfect hiding for Pedersen commitments. The
points that we will add together to hide our commitment works using some
amount of randomness which ensures the hiding property while also
allowing for some decent binding. Not perfect, as this is impossible
alongside perfect hiding. 

\begin{definition}[Pedersen Commitment]
	A Pedersen commitment, to some message, $a$, with a randomly chosen
	integer, $r$, is defined as:

	$$rH + aG$$

	where $G$ is a canonical generator for the curve and $H$ is a public
	key where no one knows $q$ such that $H = qG$.
\end{definition}

Here $r$ serves as our perfect hiding, $G$ is our generator for the
curve and $H$ is another curve point where no one knows $q$ such that
$H = qG$. This ensures perfect hiding as there is a nearly infinite
amount of possible combinations of two points that can add to any given
point. However while that is true, it does not provide perfect binding by
definition of binding and hiding. From here on we will refer to a
commitment to a message, $a$, with random value, $r$, as $C(a,r)$.

The most important property of Pedersen commitments however is
that pedersen commitments have the property of \textit{Additive
Homomorphism}:

\begin{definition}[Additive Homomorphism]
	For any two Pedersen commitments $C(a_1,r_1), C(a_2,r_2)$ we have:
	$$ C(a_1,r_1) + C(a_2,r_2) = C(a_1 + a_2, r_1 + r_2)$$
\end{definition}

This is simple to show by simply applying the definition of Pedersen
commitments: 

\eq{
	C(a_1,r_1) + C(a_2,r_2) &= r_1H + a_1G  + r_2H + a_2G \\
	                        &= (r_1 + r_2)H + (a_1 + a_2)G \\
	                        &= C(a_1+a_2,r_1+r_2)
}

Which ensures a homomorphism between the sum of commitments and the
commitment to the sum. This property will become vital when proving zero
knowledgeness later. 

Expanding on the \textit{Vector Pederson Commitment}:
\begin{definition}[Vector Pederson Commitment]
	A Vector Pedersen Commitment, to some vector of messages,
	$\textbf{v}$, with a randomly chosen integer, $r$,
	is defined as:

	$$rH + \textbf{vG}$$

	where $\textbf{G}$ is a vector of canonical generators for
	the curve and $H$ is still a private key.
\end{definition}

\subsubsection{Inner Product Proof:}

The inner product proof is a zero knowledge proof where the prover,
$\mathcal{P}$, shows knowledge of two vectors $\vec{x}$ and $\vec{y}$,
as well as their inner product, $z$, to the verifier, $\mathcal{V}$.

In order to do this the \textit{Sigma Protocol}, which is a 3-phase
protocol between verifier and prover of the form:

\begin{enumerate}
	\item $\P \rightarrow \V: \text{Commitment}$
	\item $\V \rightarrow \P: \text{Challenge}$
	\item $\P \rightarrow \V: \text{Response}$
\end{enumerate}

The prover sends a commitment to the verifier, the verifier responds with a randomly generated challenge, and finally the prover constructs a new commitment from the first commitment and the challenge... 

We will now go through each step in order with the inner product proof
in mind. The inner product, $z$, is the inner product of vectors
$\vec{x}$ and $\vec{y}$. We assume that Pedersen
commitments to these values are know:

\eq{
	C_z &= r_1 H + zG \\
	C_x &= r_2 H + \vec{xG} \\
	C_y &= r_3 H + \vec{yG} \\
}

We define two random nonce vectors $\vec{d_x}, \vec{d_y}$

\textbf{Step 1:}

\eq{
	C_{d_x} &= r_{d_x} H + \vec{d_x G} \\ 
	C_{d_y} &= r_{d_y} H + \vec{d_y G} \\
}

\eq{
	C_{0} &= r_{0} H + (\vec{d_x \cdot d_y})\ G \\
	C_{1} &= r_{1} H + (\vec{x \cdot d_x} + \vec{y \cdot d_x})\ G \\ 
}

So the prover sends:

$$\P \rightarrow \V: (C_{d_x}, C_{d_y}, C_0, C_1)$$

\textbf{Step 2:}

The verifier sends challenge $e$ to prover

$$\V \rightarrow \P: e$$

\textbf{Step 3:}

\eq{
	\vec{f_x} &= e \vec{x} + \vec{d_x} \\
	\vec{f_y} &= e \vec{y} + \vec{d_y} \\
	r_x &= e r_2 + r_{d_x} \\
	r_y &= e r_3 + r_{d_y} \\
	r_z &= e r_4 + r_{d_y} \\
}

$$\V \rightarrow \P: (\vec{f_x}, \vec{f_y}, r_x, r_y, r_z)$$

\eq{
	r_x H + \vec{f_x \cdot G} =? e C_x + C_{d_x}
}

\eq{
	r_y H + \vec{f_y \cdot G} =? e C_y + C_{d_y}
}

\eq{
	r_z H + (\vec{f_x \cdot f_y}) G =? e^2 C_z + e C_1 + C_0
}

\eq{
	\vec{G_L} &= [G_{1}, \cdots, G_{n/2}] \\
	\vec{G_R} &= [G_{n/2+1}, \cdots, G_{n}] \\
	\vec{H_L} &= [H_{1}, \cdots, H_{n/2}] \\
	\vec{H_R} &= [H_{n/2+1}, \cdots, H_{n}] \\
	\vec{a_L} &= [a_{1}, \cdots, a_{n/2}] \\
	\vec{a_R} &= [a_{n/2+1}, \cdots, a_{n}] \\
	\vec{b_L} &= [b_{1}, \cdots, b_{n/2}] \\
	\vec{b_R} &= [b_{n/2+1}, \cdots, b_{n}] \\
}

\eq{
	L_a &= \vec{a_L G_R} \\
	L_b &= \vec{b_L H_R} \\
	L   &= \vec{L_a + L_b} \\
}

\eq{
	R_a &= \vec{a_R G_L} \\
	R_b &= \vec{b_R H_L} \\
	R   &= \vec{R_a + R_b} \\
}



\subsubsection{Range Proofs:}

\subsubsection{Bulletproofs:}

%\section{State of the art:}

\subsection{Hacspec:} \label{Hacspec}

Hacspec is a subset of the programming language of Rust, designed in a
way that makes it easy to compile into theorem solvers such as Coq or F*.
The cost for having this property is a reduction in certain conventions
available in Rust not being present in Hacspec. This is a double edged
sword, both making the language simple, but also making it harder to
express certain abstract ideas. The language however is still in
development, balancing and adding features to the language.

All code written for this project was written to be Hacspec
compliant.  Our implementation is a specification meant to
be simply understood compared to a more obfuscated, but highly
optimized implementation. We will use property based testing with
QuickCheck\footnote{\url{https://github.com/BurntSushi/quickcheck}}
to check our Bulletproofs implementation against the Dalek-Cryptography
Bulletproofs\footnote{\url{https://github.com/dalek-cryptography/bulletproofs}}.
We have also created a minimal linear algebra library, in hacspec,
since it was needed for the bulletproofs implementation. Property
based testing using QuickCheck is also used for this library, testing
it against the nalgebra\footnote{\url{https://nalgebra.org/}}.

At a later time our implementation could to be compiled to Coq or F* and
proof-checked, leading to better guarantees about our implementation.
This is however not in the scope of this paper and is left to future
work. % mere her

\subsection{Ristretto:} \label{ristretto}

Ristretto is a specification of elliptic curve cryptography, created for
the specific purpose of eliminating unwanted co-factors. This was done
in order to circumvent the double-spending vulnerability. This is done
using a so-called quotient group. Also appropriately called a Factor
Group, a Quotient Group is a type of group, which takes elements from a
larger group and, using an equivalence relation, maps elements that are
'similar' to the same element in the quotient group, while preserving
most of the group structure. The remaining elements are factored out,
leaving a group with the same operations, but fewer elements. What
this means for Ristretto is that it takes points on an elliptic curve
and eliminates the co-factor by simply mapping them down to their
'equivalent' elements. This is the reason for Ristretto's somewhat
unorthodox method of doing operations, as it must ensure that each
element is computed to the proper element in the quotient group. This is
also done, in part, to allow the user to use points that are NOT in the
quotient group without worry as any computation done with these points
is automatically mapped to their proper element, thus eliminating the
rather computationally expensive operation of checking if a point is
on the proper curve.

Additionally the internal representation of the Montgomery curve we wish
to eliminate the co-factor for, is its equivalent Twisted Edwards Curve,
which is done to more easily factor points from the original curve into
the quotient group. Additionally Ristretto's equality method ensures
that equivalent representations of points on the curve are equal, even
if they are not factored into the quotient group yet. Additionally
from its encoding and decoding methods, equivalent points are encoded
to the same bitstring, and are therefore decoded into their refactored
quotient group element.

The exposed functions that were implemented are the encoding and decoding
functions, the equality function to compare points, the addition function
over points, point negation, and the derived functions from these,
namely point doubling, point subtraction and scalar multiplication. And
the final function is the One Way Map function. This function is not
entirely necessary for our purposes, but having it allows outside users
to more easily generate points from simple byte sequences, additionally
makes generating random points for testing much easier.

\section{Contributions:}

\subsection{Linear Algebra Library Specification:}
\begin{itemize}
	\item Vectors vs Matrices 
	\item Describe formulas, with sources (Dot product) 
	\item Generics :(
	\item Cloning
	\item Double indexing
	\item QuickCheck
\end{itemize} 

It was decided that the specification should of course consist of what we
need, but also of some general linear algebra functions that could be
used for others who might want to use it. The following functions was
decided to be part of the specification:

\begin{itemize}
	\item Instantiate matrix
	\item Instantiate zero filled matrix
	\item (Instantiate one filled matrix)
	\item Instantiate identity matrix
	\item Transposition
	\item Slicing
	\item (Scalar Multiplication)
	\item Addition
	\item Subtraction
	\item Hadamard product
	\item Matrix Multiplication
\end{itemize}

No generalized standard for Linear Algebra Specification.

\subsection{Implementing Ristretto:} \label{implementing-ristretto}

For our Ristretto implementation on 25519 there
exists an IETF-standard specification of exactly
this, which was used as a guide for our implementation.
\footnote{\url{https://www.ietf.org/archive/id/draft-irtf-cfrg-ristretto255-00.html}}
This specification was very helpful and after inspecting the code we
are testing against closely, it is clear that they used this standard
as well.

The most important things to note about this standard, outside the
explicit formulas used for its various methods are which functions and
internal representations we are allowed to expose to the outside. Namely
that the only functions we may expose were encoding of points, decoding
of encoded points, the map which is used for creating points, point
addition, point negation, point subtraction, scalar multiplication. The
last two were allowed purely from being derivable from repeated
application of point addition and/or negation. Some things that were not
allowed to be exposed under any circumstances, are the internal
representations of either points or its field elements or any functions
that are not the ones mentioned above, which is as expected for something
that is meant to be a thin layer of abstraction beneath an implementation
of 25519.

Each internal point representation is composed of four field elements
$(X : Y : Z :T)$. Field-elements, as defined by the standard are values
modulo p, with p being the prime field for 25519, $2^{255} - 19$. This
was achieved using the \texttt{public\_nat\_mod!} macro which defines
fields over certain values which just so happen to accept hex values as
modulo values, which was very convenient. With this we are now able to
create field elements using various functions and properties that are
native to the type created by \texttt{public\_nat\_mod!}. Most of the
standard integer operators like addition, subtraction and multiplication
are implemented for these field elements for example. An important thing
to note is that the internal calculations for division is done using
integer arithmetic rather than finite field arithmetic, however the
few times where division is used directly it is ensured that the result
in finite field arithmetic is equal to the integer arithmetic solution.

Additionally the standard, specified a series of constants. These
constants were too large to be implemented as integers. Additionally
hacspec did not allow for us to simply use the \texttt{from\_hex()}
method. As such, after converting each of these constants into their
corresponding hex-values, we built them as byte sequences for which
we had an equivalent \texttt{from\_byte\_seq\_be} which created the
correct field elements we wanted.

While it is impossible for a legal point to be encoded and then have the
decoding on its encoding fail, the decoding method has several checks
that ensure that the input given is legal. The primary reason for this
is that decoding is a method available to the client and as such there is
no guarantee that the byte-strings they want to decode are necessarily
legal points that they first encoded properly, but could be artificially
constructed byte-strings. We want to avoid this and thus the standard has
a list of properties the byte-string input and attempted decoding must
fulfill in order to be canonical. 

\subsection{Implementing Bulletproofs:}

Our bulletproofs implementation was implemented on the foundation of our
implementations of Linear Algebra and Ristretto. The first and simplest
step was implementing Pedersen commitments to single values as well as to
vectors. From our implementation of Ristretto we can easily add points to
each other and multiply points by a scalar. This is essentially the only
thing a Pedersen commitment is. Additionally we needed it to support
vector commitments. From our implementation of Linear Algebra we could
easily adapt this into the code. This implementation was nearly trivial
given the base we built it upon.

The next step in the process towards implementing Bulletproofs is the
inner product proof. The implementation of which does not lean itself
against our Ristretto implementation as our implementation of Pedersen
commitments did, however it does utilize said Pedersen commitments. 

\subsection{Analysis of coding stuff:}

\subsection{Summary of coding stuff:}

\subsection{Conclusions on our work:}

\section{Future work:}

\section{Acknowledgements:}

%% TAK TIL FRANZISKUS
%% Lasse?

\section{References}
\printbibliography


\end{document}
